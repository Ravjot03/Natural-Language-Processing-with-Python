{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V23WPqCXJ4w8",
        "outputId": "3a7204d2-7a26-473d-9cc5-bdefe2a06f27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "nxRThil1HtNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GvJCp32PE3bX"
      },
      "outputs": [],
      "source": [
        "tweet = \"Sometimes to understand a word's meaning you need more than a definition. you need to see the word used in a sentence. At YourDictionary, we give you the tools to learn what a word means and how to use it correctly. With this sentence maker, simply type a word in the search bar and see a variety of sentences with that word used in its different ways. Our sentence generator can provide more context and relevance, ensuring you use a word the right way.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI6-VNoQFeis",
        "outputId": "99d6667e-b662-43f5-a6a8-8f8b23930e3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello! how are you?\""
      ],
      "metadata": {
        "id": "IFxDqiBLFub-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "q5spTeppFlFL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tok = word_tokenize(text)\n",
        "word_tok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEkKX9GuFobW",
        "outputId": "84f53738-f3e5-444e-c331-382a76880d9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', '!', 'how', 'are', 'you', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tok = sent_tokenize(tweet)\n",
        "sent_tok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2-LbFBRF4LQ",
        "outputId": "4b5aaddd-097b-4716-e8c4-256d88d479b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Sometimes to understand a word's meaning you need more than a definition.\",\n",
              " 'you need to see the word used in a sentence.',\n",
              " 'At YourDictionary, we give you the tools to learn what a word means and how to use it correctly.',\n",
              " 'With this sentence maker, simply type a word in the search bar and see a variety of sentences with that word used in its different ways.',\n",
              " 'Our sentence generator can provide more context and relevance, ensuring you use a word the right way.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## There are 3 types of sentence tokenize."
      ],
      "metadata": {
        "id": "mqRU1G0AGMQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "print(tokenizer.tokenize(tweet))\n",
        "print(\"Length of tokenizer: \",len(tokenizer.tokenize(tweet)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvsRG5f1GL5Q",
        "outputId": "e37744e6-d58e-46ff-95c1-db1f2081d340"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sometimes', 'to', 'understand', 'a', 'word', \"'s\", 'meaning', 'you', 'need', 'more', 'than', 'a', 'definition.', 'you', 'need', 'to', 'see', 'the', 'word', 'used', 'in', 'a', 'sentence.', 'At', 'YourDictionary', ',', 'we', 'give', 'you', 'the', 'tools', 'to', 'learn', 'what', 'a', 'word', 'means', 'and', 'how', 'to', 'use', 'it', 'correctly.', 'With', 'this', 'sentence', 'maker', ',', 'simply', 'type', 'a', 'word', 'in', 'the', 'search', 'bar', 'and', 'see', 'a', 'variety', 'of', 'sentences', 'with', 'that', 'word', 'used', 'in', 'its', 'different', 'ways.', 'Our', 'sentence', 'generator', 'can', 'provide', 'more', 'context', 'and', 'relevance', ',', 'ensuring', 'you', 'use', 'a', 'word', 'the', 'right', 'way', '.']\n",
            "Length of tokenizer:  89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer_w = WordPunctTokenizer()\n",
        "print(tokenizer_w.tokenize(tweet))\n",
        "print(len(tokenizer_w.tokenize(tweet)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb0ZFkobGswC",
        "outputId": "367a2495-0257-435d-b81c-3cb0b34b2022"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sometimes', 'to', 'understand', 'a', 'word', \"'\", 's', 'meaning', 'you', 'need', 'more', 'than', 'a', 'definition', '.', 'you', 'need', 'to', 'see', 'the', 'word', 'used', 'in', 'a', 'sentence', '.', 'At', 'YourDictionary', ',', 'we', 'give', 'you', 'the', 'tools', 'to', 'learn', 'what', 'a', 'word', 'means', 'and', 'how', 'to', 'use', 'it', 'correctly', '.', 'With', 'this', 'sentence', 'maker', ',', 'simply', 'type', 'a', 'word', 'in', 'the', 'search', 'bar', 'and', 'see', 'a', 'variety', 'of', 'sentences', 'with', 'that', 'word', 'used', 'in', 'its', 'different', 'ways', '.', 'Our', 'sentence', 'generator', 'can', 'provide', 'more', 'context', 'and', 'relevance', ',', 'ensuring', 'you', 'use', 'a', 'word', 'the', 'right', 'way', '.']\n",
            "94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "\n",
        "Stemming is basically removing the suffix from a word and reduce it to its root word.\n",
        "\n",
        "For eg - 'Flying'- removing 'ing' suffix and getting the root word 'Fly'"
      ],
      "metadata": {
        "id": "kKqajSC6HraZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Porter Stemmer"
      ],
      "metadata": {
        "id": "DcqScMoKIo_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemming = PorterStemmer()\n",
        "word = 'danced'\n",
        "stemming.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tet5zHlyHsqm",
        "outputId": "98efb64b-e2c0-4b00-d0bc-83856ded5d72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'danc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the root word is incorrect. it should be 'dance', but it is giving 'danc'."
      ],
      "metadata": {
        "id": "w-Uz_NwNJCIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'replacement'\n",
        "stemming.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FaXIhzOdJMWi",
        "outputId": "dfef5ef9-3b37-4f90-9336-6ab7fc82d278"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'replac'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'happiness'\n",
        "stemming.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K8u_HaI3JRDq",
        "outputId": "17f90a57-2d8b-4279-faa5-f0705f28e63f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is giving wrong outputs to us. Now we will try Lancaster Stemmer operations."
      ],
      "metadata": {
        "id": "Sb2flDTWJaj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lancaster Stemmer"
      ],
      "metadata": {
        "id": "A_fLH-8iLB3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemming1 = LancasterStemmer()\n",
        "word = 'happily'\n",
        "stemming1.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "64-NOHl6Jmhs",
        "outputId": "b2a5688f-dd23-4c67-8a76-2040842c6daf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular Expression Stemmer"
      ],
      "metadata": {
        "id": "s-qNHOVLLD4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "stemming2 = RegexpStemmer('ing$|s$|e$|able$|ness$', min=3)\n",
        "word = 'raining'\n",
        "stemming2.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HT5pF6fIK_4P",
        "outputId": "57eed2d6-4be1-4671-9387-cd01a0c5dbda"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'flying'\n",
        "stemming2.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PvYh6pszL2VB",
        "outputId": "f1146d87-c40a-4850-9e73-0041226796f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fly'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'happiness'\n",
        "stemming2.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zzCqJnL8MLrq",
        "outputId": "4d76ec0d-3386-425c-cf07-b1e325e2c543"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Snowball Stemmer"
      ],
      "metadata": {
        "id": "CimjfQ6WOs2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"snowball_data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrk3FEjVOu-4",
        "outputId": "1c7cb568-aef2-43dd-ed8b-00d4363e49e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package snowball_data to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "stemming3 = SnowballStemmer(\"english\")\n",
        "word = 'happiness'\n",
        "stemming3.stem(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qem6qBjGO3Dk",
        "outputId": "1e4d5b70-91fb-452a-c0b5-76c1f07ec3aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming3 = SnowballStemmer(\"arabic\")\n",
        "word = 'تحلق'\n",
        "stemming3.stem(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NWOakvD3PMg-",
        "outputId": "c3d928e8-7198-435c-ce30-86ad4ad10e96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'تحلق'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Snowball stemmer can be used with different languages.\n",
        "\n",
        "Best stemmers are Lancaster and Snowball stemmer."
      ],
      "metadata": {
        "id": "QRKaDi_2PtLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\n",
        "\n",
        "Lemmatization is mainly used for chatbots."
      ],
      "metadata": {
        "id": "YX0jSxcVtLSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3SwrOdgP0R0",
        "outputId": "a5502185-5317-4fbb-b4b7-cb4032859953"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These packages like punkt, snowball_data, wordnet are already loaded with lots of data."
      ],
      "metadata": {
        "id": "FQG99Nv9t3t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatizer.lemmatize('going', pos= 'v')\n",
        "words = [(\"eating\",'v'),(\"playing\", 'v')]\n",
        "\n",
        "for word, pos in words:\n",
        "  print(lemmatizer.lemmatize(word, pos = pos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y_KiXiRtwd1",
        "outputId": "1ee4da95-adcc-4089-aaad-3e7a33707fdf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eat\n",
            "play\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-706kPGCuIKo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
